{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import HTML, display\n",
    "#display(HTML(\"<table><tr><td><img src='data/image2.jpg' width='700'></td><td><img src='data/image1.jpeg' width='240'></td></tr></table>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the cell below to install libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U spaCy\n",
    "#!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to load libaries and pre-defined functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries and helper code\n",
    "#from helper_code.book import *\n",
    "import re\n",
    "from pylab import rcParams\n",
    "import spacy\n",
    "import urllib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def get_book_df(chapters):\n",
    "    book_df = pd.DataFrame(columns=[\"text\", \"part-of-speech\",\"lemma\",\"chapter\"])\n",
    "    for i in range(len(chapters)):\n",
    "        chapter_tokens = nlp(chapters[i])\n",
    "        for token in chapter_tokens:\n",
    "             if ((token.pos_==\"VERB\") | (token.pos_==\"NOUN\") | (token.pos_==\"ADJ\") | (token.pos_== \"PROPN\")):\n",
    "                    book_df = book_df.append({\"text\": token.text,\n",
    "                             \"part-of-speech\":  token.pos_,\n",
    "                             \"lemma\" : token.lemma_.strip().lower(),\n",
    "                             \"chapter\": i+1\n",
    "                              }, ignore_index=True)\n",
    "    return book_df\n",
    "\n",
    "\n",
    "def get_speechparts_by_chapter(book_df):\n",
    "    result = book_df.groupby([\"chapter\", \"part-of-speech\"]).size().reset_index(name=\"count\").\\\n",
    "                          pivot(index=\"chapter\", columns='part-of-speech',values=\"count\").reset_index().\\\n",
    "                          rename_axis(None,axis=\"columns\").set_index(\"chapter\")\n",
    "    return result \n",
    "\n",
    "def get_counts(book_df, value):\n",
    "    result = book_df.groupby(value).size().reset_index(name='count').set_index(value).sort_values(['count'], ascending=False)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def get_counts_by_chapters(book_df):\n",
    "    result = book_df.groupby([\"chapter\", \"lemma\"]).size().reset_index(name=\"count\").\\\n",
    "                                     pivot(index=\"chapter\", columns='lemma',values=\"count\").reset_index().\\\n",
    "                                    rename_axis(None,axis=\"columns\").set_index(\"chapter\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group goal\n",
    "\n",
    " \n",
    "Go through the \"Alice's Adventures in Wonderland\" analysis below, work on challenges, and try modifying the code.\n",
    "\n",
    "**Extra challenge**:\n",
    "\n",
    "Explore the \"Adventures of Tom Sawyer\" book to show interesting results and visualizations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download  book from project Guttenberg website\n",
    "\n",
    "This book was downloaded from project Gutenberg website.\n",
    "\n",
    "**Project Gutenberg** is a library of over 60,000 free eBooks\n",
    "\n",
    "[This link](http://www.gutenberg.org/ebooks/search/?sort_order=downloads) shows the most popular books. \n",
    "\n",
    "\n",
    "In this notebook we are going to look at \"Alice's Adventures in Wonderland\" book.  \n",
    "\"The Adventures of Tom Sawyer\" is downloaded as well for extra challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_filename = \"alice.txt\"\n",
    "tom_filename = \"tom.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if reading from cloud object storage\n",
    "alice_url=\"https://swift-yeg.cloud.cybera.ca:8080/v1/AUTH_d22d1e3f28be45209ba8f660295c84cf/hackaton/alice.txt\"\n",
    "urllib.request.urlretrieve(alice_url, alice_filename)\n",
    "\n",
    "\n",
    "tom_url=\"https://swift-yeg.cloud.cybera.ca:8080/v1/AUTH_d22d1e3f28be45209ba8f660295c84cf/hackaton/tom.txt\"\n",
    "urllib.request.urlretrieve(tom_url, tom_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(alice_filename, 'r') as text_file:\n",
    "    book = text_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the entire book on the screen\n",
    "print(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many characters are in the book?\n",
    "len(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the book by chapter\n",
    "chapters = re.split(\"CHAPTER\\s+[IVXLCDM]+.\", book)\n",
    "\n",
    "# strip off any whitespace at the very beginning and very end of each chapter.\n",
    "chapters = [chapter.strip() for chapter in chapters]\n",
    "\n",
    "# remove tabs\n",
    "chapters = [re.sub(\"\\n\", \" \", c) for c in chapters]\n",
    "\n",
    "#select only chapters that have more than 1000 characters (to exclude table of contents, title, etc.)\n",
    "chapters = [c for c in chapters if len(c)>1000]\n",
    " \n",
    "# number of chapters\n",
    "print(len(chapters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe selecting only nouns, proper nouns, verbs. and adjectives per chapter\n",
    "\n",
    "- **text**: actual word\n",
    "- **part-of-speech**:  ADJ, PROPN, VERB, or NOUN\n",
    "- **lemma**: headword\n",
    "- **chapter**: chapter number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell will run 3-5 mins!!!\n",
    "\n",
    "#create a dataframe from the book\n",
    "book_df = get_book_df(chapters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 5 rows of the dataframe\n",
    "book_df.head()\n",
    "\n",
    "## try experimenting with \"head\" function, like head(20), head(5), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how many rows (indiviadual words) and columns do we have?\n",
    "book_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of adjectives, nouns, proper nouns, and verbs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we group by \"part-of-speech\" column and count the number of rows\n",
    "book_df.groupby(\"part-of-speech\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure size 5 by 5 inches\n",
    "rcParams['figure.figsize'] = 5, 5\n",
    "\n",
    "#create a pie chart\n",
    "book_df.groupby(\"part-of-speech\").size().plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: \n",
    " - Try grouping by different column: if you change `groupby(\"part-of-speech\")` to `groupby(\"chapter\")` what will it give you?\n",
    " - Experiment with different kinds of plots: try  changing `plot.pie()` to `plot()` or `plot.bar()` or `plot.barh()`. Which of these better represents the data?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of adjective/nouns/proper nouns and verbs  per chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we call a function to get total number of all parts of speech per chapter\n",
    "speech_parts_by_chapter = get_speechparts_by_chapter(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print data on the screen\n",
    "speech_parts_by_chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure size 18 by 5 inches\n",
    "rcParams['figure.figsize'] = 18, 5\n",
    "\n",
    "#different kind of plot - area\n",
    "speech_parts_by_chapter.plot.area()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "Experiment with plots: try changing `plot.area()` to `plot()` or `plot.bar()` or even `plot.bar(stacked=True`. \n",
    "\n",
    "What kind of plot can better visually demonstrate which chapter has the largest number of verbs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way to find the chapter with max number of words is **sorting**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort_values() function - sorts by a column or set of columns\n",
    "speech_parts_by_chapter.sort_values(\"VERB\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    " - find the  chapter that has the most **NOUN**s\n",
    " - find the chapter that hast the **fewest** adjectives\n",
    " - try plotting the results\n",
    " - try two new kinds of plots - [histogram](https://www.mathsisfun.com/data/histograms.html) and [boxplot](https://www.mathsisfun.com/definitions/box-and-whisker-plot.html). Can you figure out how to interpret them?\n",
    " - add `.boxplot()`\n",
    " - add `.plot.hist(alpha=0.4)` (try changing alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function to count the number of rows  for every \"lemma\"\n",
    "word_counts = get_counts(book_df, \"lemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print top 10 most frequent words on the screen\n",
    "word_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    " - try using \"text\" column instead of \"lemma\" - why do you get different results?\n",
    " - plot the results using your choice of plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The top 10 most common adjectives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## subset only to adjectives\n",
    "adjectives = book_df[book_df[\"part-of-speech\"]==\"ADJ\"]\n",
    "\n",
    "adjectives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function to count the number of adjectives\n",
    "adjective_counts = get_counts(adjectives, \"lemma\")\n",
    "\n",
    "adjective_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure size 18 by 8 inches\n",
    "rcParams['figure.figsize'] = 18, 8\n",
    "\n",
    "#visualize the top 10 adjectives:\n",
    "adjective_counts.head(10).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    " - find the top 10 most common nouns and verbs\n",
    " - plot the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the top 15 most common  proper nouns, how does the number vary from chapter to chapter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## subset only to proper nouns\n",
    "propnouns = book_df[book_df[\"part-of-speech\"]==\"PROPN\"]\n",
    "\n",
    "propnouns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many most frequent proper nouns do we want to analyse\n",
    "num_words = 15\n",
    "\n",
    "#call function to count the number of proper nouns\n",
    "top_propnouns = get_counts(propnouns, \"lemma\")\n",
    "\n",
    "#get the top proper nouns (excluding counts counts)\n",
    "top_propnouns = top_propnouns.head(num_words).index\n",
    "\n",
    "#transform them into list\n",
    "top_propnouns = list(top_propnouns)\n",
    "\n",
    "#print on the screen\n",
    "top_propnouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## subset only to the top proper nouns\n",
    "character_by_chapter = book_df[book_df[\"lemma\"].isin(top_propnouns)]\n",
    "\n",
    "character_by_chapter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#what is the distribution of top proper nouns per chapter?\n",
    "# call function to form resulting dataframe\n",
    "counts_by_chapter = get_counts_by_chapters(character_by_chapter)\n",
    "\n",
    "#display on the screen\n",
    "counts_by_chapter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure size 18 by 8 inches\n",
    "rcParams['figure.figsize'] = 18, 8\n",
    "\n",
    "#what are the main characters in every chapter?\n",
    "#we use colormap \"tab20\" to extend the default number of colors\n",
    "counts_by_chapter.plot.bar(stacked = True, cmap=\"tab20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    " - Try experimenting with the number of proper nouns (change `num_words`)\n",
    " - Try doing the same thing with adjectives, nouns, or/and verbs - can you guess whats going on in each chapter based on these plots?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra\n",
    "Now let's try doing the same thing but using **percentage** instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will make a copy of dataframe to work with percentages\n",
    "counts_percent = counts_by_chapter.copy()\n",
    "\n",
    "#create addtional column - sum of words per chapter (axis =1 - means -sum by row)\n",
    "counts_percent[\"sum\"] = counts_percent.sum(axis = 1)\n",
    "\n",
    "#divide evry column by sum\n",
    "counts_percent = counts_percent.iloc[:,0:num_words].divide(counts_percent[\"sum\"],axis=0)\n",
    "\n",
    "#multiply every column by 100\n",
    "counts_percent = counts_percent.iloc[:,0:num_words].multiply(100,axis=0)\n",
    "\n",
    "#figure size 18 by 8 inches\n",
    "rcParams['figure.figsize'] = 18,8\n",
    "\n",
    "#we choose area plot this time\n",
    "counts_percent.plot.area(cmap=\"tab20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
